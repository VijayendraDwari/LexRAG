{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T12:56:26.276563Z","iopub.execute_input":"2025-04-03T12:56:26.276854Z","iopub.status.idle":"2025-04-03T12:56:26.574410Z","shell.execute_reply.started":"2025-04-03T12:56:26.276823Z","shell.execute_reply":"2025-04-03T12:56:26.573550Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Install required libraries\n!pip install bitsandbytes networkx datasets transformers sentence-transformers torch accelerate langchain langchain-community duckduckgo-search feedparser -q\n\n# Hugging Face login\nfrom huggingface_hub import login\nlogin(\"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\")\n\n# Suppress logging\nimport logging\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\nlogging.getLogger(\"datasets\").setLevel(logging.ERROR)\n\n# Core Imports\nimport torch\nimport feedparser\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom langchain.llms.base import LLM\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.agents import initialize_agent, AgentType\nfrom langchain.tools import Tool\nfrom typing import Any\nfrom pydantic import PrivateAttr\nfrom duckduckgo_search import DDGS\n\n# âœ… Model Setup\nMODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float32,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\ntokenizer.pad_token = tokenizer.eos_token\nprint(\"\\nğŸš€ Model successfully loaded! ğŸš€\")\n\n# âœ… Custom LLM Wrapper\nclass GraphRAGLLM(LLM):\n    _model: Any = PrivateAttr()\n    _tokenizer: Any = PrivateAttr()\n    max_new_tokens: int = 512\n    device: str = \"cuda\"\n\n    def __init__(self, model, tokenizer, max_new_tokens=512, device=\"cuda\", **kwargs):\n        super().__init__(**kwargs)\n        self._model = model\n        self._tokenizer = tokenizer\n        self.max_new_tokens = max_new_tokens\n        self.device = device\n\n    @property\n    def _llm_type(self) -> str:\n        return \"graph-rag-llm\"\n\n    def _call(self, prompt: str, stop=None) -> str:\n        inputs = self._tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512, padding=True).to(self.device)\n        with torch.no_grad():\n            outputs = self._model.generate(inputs[\"input_ids\"], max_new_tokens=self.max_new_tokens, temperature=0.5, top_p=0.8, pad_token_id=self._tokenizer.pad_token_id)\n        decoded_output = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n        return decoded_output.split(\"Answer:\")[-1].strip() if \"Answer:\" in decoded_output else decoded_output.strip()\n\nllm = GraphRAGLLM(model=model, tokenizer=tokenizer)\n\n# âœ… Smart DuckDuckGo Search\ndef duckduckgo_search(query: str, num_results: int = 5) -> str:\n    results = []\n    with DDGS() as ddgs:\n        for r in ddgs.text(query, max_results=num_results):\n            results.append(f\"{r['title']}: {r['href']}\")\n    return \"\\n\".join(results) if results else \"No relevant real-time results found.\"\n\n# âœ… OFAC RSS Feed Reader\ndef ofac_rss_feed_tool(query: str) -> str:\n    feed_url = \"https://home.treasury.gov/rss/press-releases.xml\"\n    feed = feedparser.parse(feed_url)\n    matches = [entry for entry in feed.entries if \"ofac\" in entry.title.lower() or \"sanctions\" in entry.title.lower()]\n    filtered = [entry for entry in matches if query.lower() in entry.title.lower() or query.lower() in entry.summary.lower()]\n    \n    if not filtered:\n        return \"No matching OFAC-related items found in the latest Treasury press releases.\"\n    \n    return \"\\n\".join([f\"{entry.title} - {entry.link}\" for entry in filtered[:5]])\n\n# âœ… Combined Agent Logic: use both tools, then LLM to summarize\ndef run_combined_agent(query: str) -> str:\n    print(f\"\\nğŸ” Query: {query}\")\n    \n    # Step 1: Get DuckDuckGo results\n    ddg_results = duckduckgo_search(query)\n\n    # Step 2: Get OFAC feed results\n    ofac_results = ofac_rss_feed_tool(query)\n\n    # Step 3: Combine results and summarize with LLM\n    combined_context = f\"Real-time results:\\n{ddg_results}\\n\\nOfficial OFAC/Treasury results:\\n{ofac_results}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n    response = llm._call(combined_context)\n\n    print(\"âœ… Final Answer:\\n\", response)\n    return response\n\n# âœ… Questions to Test\nqueries = [\n    \"Are there any new OFAC sanctions on North Korea in 2025? Check official updates and current news.\",\n    \"Has OFAC released any new sanctions related to Iran recently? Look into real-time sources and Treasury press releases.\",\n    \"What are the latest OFAC sanctions related to crypto or digital currencies? Summarize any relevant Treasury announcements.\"\n]\n\n# âœ… Run Each Query with Fresh Context and Print\nfor q in queries:\n    memory = ConversationBufferMemory(memory_key=\"chat_history\")  # Reset memory\n    run_combined_agent(q)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T12:56:26.575363Z","iopub.execute_input":"2025-04-03T12:56:26.575759Z","iopub.status.idle":"2025-04-03T12:58:39.253507Z","shell.execute_reply.started":"2025-04-03T12:56:26.575733Z","shell.execute_reply":"2025-04-03T12:58:39.252697Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.4/423.4 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"121dc67822d3467fbe2cc6c563585585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e45b7c36fa400fbbc518821186028b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8625806e092485e9be1f6239ab260bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"869533d7a4c64cd5b728f97205b0101a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8385157f72834e2fa3ee323e8d26b63a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51f064bed67c402e9cb3c55f40c1664e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6b291be1db448ab66177377ccf97be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e2b992ae99640f9889d53565dc44b7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc64e00655dc46b481d54450f8e7b8ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27db811977f14ba4adf00f1602a6dc3d"}},"metadata":{}},{"name":"stdout","text":"\nğŸš€ Model successfully loaded! ğŸš€\n\nğŸ” Query: Are there any new OFAC sanctions on North Korea in 2025? Check official updates and current news.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-2-34940b03a2f0>:116: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n  memory = ConversationBufferMemory(memory_key=\"chat_history\")  # Reset memory\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"âœ… Final Answer:\n No matching OFAC-related items found in the latest Treasury press releases.\n\nNote: OFAC updates are typically released on Fridays, so this information might change as new updates are released. I recommend checking the official OFAC website for the most current information. \n\nFor the latest information on sanctions against North Korea, I recommend checking the following sources:\n\n1.  Official OFAC website: https://ofac.treasury.gov/\n2.  U.S. Department of State: https://www.state.gov/\n3.  U.S. Department of the Treasury: https://home.treasury.gov/\n4.  Korea JoongAng Daily: https://koreajoongangdaily.joins.com/\n5.  North Korea Sanctions - Office of Foreign Assets Control: https://ofac.treasury.gov/sanctions-programs-and-country-information/north-korea-sanctions\n\nPlease note that the information provided is accurate as of my last update. For the most recent information, I recommend checking the official sources mentioned above.\n\nğŸ” Query: Has OFAC released any new sanctions related to Iran recently? Look into real-time sources and Treasury press releases.\nâœ… Final Answer:\n Yes, according to the latest Treasury press releases, OFAC has released new sanctions related to Iran. You can find the latest information on the Treasury Department's website.\n\nHere are some real-time sources and Treasury press releases:\n\n*   [OFAC Related Press Releases - Office of Foreign Assets Control](https://ofac.treasury.gov/press-releases)\n*   [Treasury Sanctions Entities in Iran and Russia That Attempted to...](https://home.treasury.gov/news/press-releases/jy2766)\n*   [The Departments of Treasury and Justice Take Action Against Iranian...](https://home.treasury.gov/news/press-releases/sb0066)\n*   [US slaps Iran-related sanctions on oil tankers, China 'teapot' refinery...](https://www.reuters.com/world/us-issues-fresh-iran-related-sanctions-treasury-dept-says-2025-03-20/)\n*   [Iran-related Designation and Designation update; Hostages and...](https://ofac.treasury.gov/recent-actions/20230918)\n\nThese sources provide the latest information on OFAC-related sanctions and designations. You can visit the Treasury Department's website for the most up-to-date information.\n\nğŸ” Query: What are the latest OFAC sanctions related to crypto or digital currencies? Summarize any relevant Treasury announcements.\nâœ… Final Answer:\n As of the latest Treasury press release, there are no matching OFAC-related items found. However, please note that sanctions and regulatory guidance can change rapidly. To stay up-to-date, please visit the official OFAC website or Treasury press releases for the latest information.\n\nIf you're looking for the latest guidance on virtual currency sanctions, I recommend checking out the following resources:\n\n1.  The Office of Foreign Assets Control (OFAC) website: [www.ofac.treasury.gov](http://www.ofac.treasury.gov)\n2.  The Treasury Department's press releases: [treasury.gov](http://treasury.gov)\n3.  The Chainalysis OFAC Sanctions Tracker: [www.chainalysis.com](http://www.chainalysis.com)\n\nThese resources will provide you with the most current information on virtual currency sanctions and any relevant updates to OFAC regulations.\n","output_type":"stream"}],"execution_count":2}]}